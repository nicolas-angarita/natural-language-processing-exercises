{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d04e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire as a\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f726ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5198b",
   "metadata": {},
   "source": [
    "### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "    - Lowercase everything\n",
    "    - Normalize unicode characters\n",
    "    - Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9e73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(string):\n",
    "    string = string.lower()\n",
    "    string = unicodedata.normalize('NFKD', string).encode('ascii', 'ignore').decode('utf-8')\n",
    "    string = re.sub(r'[^a-z0-9\\'\\s]', '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63706b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angarta'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean('Angarta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd7ead8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'angarita'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean('Angaríta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f8ee32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"angarita 's'\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(\"Angaríta '!s'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1615e0a",
   "metadata": {},
   "source": [
    "### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daca4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    string = tokenize.tokenize(string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c476343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'my', 'name', 'is', 'nico']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize('hello my name is nico')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7343dc",
   "metadata": {},
   "source": [
    "### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e2db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    \n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in text]\n",
    "    # glue it back together with spaces, as it was before\n",
    "    text = ' '.join(stems)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f902add3",
   "metadata": {},
   "source": [
    "### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf682e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    \n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "   \n",
    "    lemmas = [wnl.lemmatize(word) for word in text]\n",
    "    \n",
    "    text = ' '.join(lemmas)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d959da",
   "metadata": {},
   "source": [
    "### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    " - This function should define two optional parameters, extra_words and exclude_words.\n",
    " - These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5b33827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(string, extra_words = [], exclude_words = []):\n",
    "\n",
    "    stopword_list = stopwords.words('english')\n",
    "\n",
    "    stopword_list = set(stopword_list) - set(exclude_words)\n",
    "\n",
    "    stopword_list = stopword_list.union(set(extra_words))\n",
    "    \n",
    "    words = string #.split()\n",
    "    \n",
    "    filtered_words = [word for word in words.split() if word not in stopword_list]\n",
    "    \n",
    "    string_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef53b242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I would like 1 million dollars, I could buy lot stuff'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('I would like a 1 million dollars, because I could buy a lot of stuff')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575107a",
   "metadata": {},
   "source": [
    "### 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d4e70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bill Gates meets Ratan Tata, N Chandrasekaran;...</td>\n",
       "      <td>Microsoft Co-founder Bill Gates met with Tata ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SoftBank sells shares worth ₹954 crore in logi...</td>\n",
       "      <td>SoftBank sold shares worth ₹954 crore in logis...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smriti Irani's 2011 tweet on LPG price hike re...</td>\n",
       "      <td>Hours after the central government raised the ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indian-Americans Renjen, Subramaniam to be mem...</td>\n",
       "      <td>Indian-Americans Punit Renjen and Rajesh Subra...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adani denies report of securing $3 bn from sov...</td>\n",
       "      <td>Adani Group has denied a report which claimed ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Grateful to Mohit for letting me record 'Galli...</td>\n",
       "      <td>Actress Shraddha Kapoor said that she is \"grat...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Amitabh Bachchan to play lead role in Ribhu Da...</td>\n",
       "      <td>Actor Amitabh Bachchan will play the lead role...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Was difficult, especially for mom: Arbaaz on f...</td>\n",
       "      <td>Actor Arbaaz Khan, speaking about the time aft...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Pak singer Ali Zafar shares old video of Dilip...</td>\n",
       "      <td>Pakistani singer Ali Zafar shared an old video...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rajamouli has broken the walls of cinema in In...</td>\n",
       "      <td>Actor Rana Daggubati, speaking about the succe...</td>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Bill Gates meets Ratan Tata, N Chandrasekaran;...   \n",
       "1   SoftBank sells shares worth ₹954 crore in logi...   \n",
       "2   Smriti Irani's 2011 tweet on LPG price hike re...   \n",
       "3   Indian-Americans Renjen, Subramaniam to be mem...   \n",
       "4   Adani denies report of securing $3 bn from sov...   \n",
       "..                                                ...   \n",
       "95  Grateful to Mohit for letting me record 'Galli...   \n",
       "96  Amitabh Bachchan to play lead role in Ribhu Da...   \n",
       "97  Was difficult, especially for mom: Arbaaz on f...   \n",
       "98  Pak singer Ali Zafar shares old video of Dilip...   \n",
       "99  Rajamouli has broken the walls of cinema in In...   \n",
       "\n",
       "                                              content       category  \n",
       "0   Microsoft Co-founder Bill Gates met with Tata ...       business  \n",
       "1   SoftBank sold shares worth ₹954 crore in logis...       business  \n",
       "2   Hours after the central government raised the ...       business  \n",
       "3   Indian-Americans Punit Renjen and Rajesh Subra...       business  \n",
       "4   Adani Group has denied a report which claimed ...       business  \n",
       "..                                                ...            ...  \n",
       "95  Actress Shraddha Kapoor said that she is \"grat...  entertainment  \n",
       "96  Actor Amitabh Bachchan will play the lead role...  entertainment  \n",
       "97  Actor Arbaaz Khan, speaking about the time aft...  entertainment  \n",
       "98  Pakistani singer Ali Zafar shared an old video...  entertainment  \n",
       "99  Actor Rana Daggubati, speaking about the succe...  entertainment  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = a.get_news_blog_articles()\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226db72",
   "metadata": {},
   "source": [
    "### 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "215f3564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>If you’re interested in embarking on a career ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codeup Among Top 58 Best Coding Bootcamps of 2023</td>\n",
       "      <td>Codeup is pleased to announce we have been ran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "5  Codeup Among Top 58 Best Coding Bootcamps of 2023   \n",
       "\n",
       "                                             content  \n",
       "0  Black excellence in tech: Panelist Spotlight –...  \n",
       "1  Black excellence in tech: Panelist Spotlight –...  \n",
       "2  Black excellence in tech: Panelist Spotlight –...  \n",
       "3  Black excellence in tech: Panelist Spotlight –...  \n",
       "4  If you’re interested in embarking on a career ...  \n",
       "5  Codeup is pleased to announce we have been ran...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = a.acquire_codeup()\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab372c",
   "metadata": {},
   "source": [
    "### 8. For each dataframe, produce the following columns:\n",
    "\n",
    "    - title to hold the title\n",
    "    - original to hold the original article/post content\n",
    "    - clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "    - stemmed to hold the stemmed version of the cleaned data.\n",
    "    - lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08842fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title', 'content']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean, stemmed, and lemmatized columns\n",
    "codeup_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d01d6c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>If you’re interested in embarking on a career ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codeup Among Top 58 Best Coding Bootcamps of 2023</td>\n",
       "      <td>Codeup is pleased to announce we have been ran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "5  Codeup Among Top 58 Best Coding Bootcamps of 2023   \n",
       "\n",
       "                                            original  \n",
       "0  Black excellence in tech: Panelist Spotlight –...  \n",
       "1  Black excellence in tech: Panelist Spotlight –...  \n",
       "2  Black excellence in tech: Panelist Spotlight –...  \n",
       "3  Black excellence in tech: Panelist Spotlight –...  \n",
       "4  If you’re interested in embarking on a career ...  \n",
       "5  Codeup is pleased to announce we have been ran...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df.rename(columns={'content':'original'},  inplace= True)\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d453915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'black excellence in tech panelist spotlight  wilmarie de la cruz mejia\\n\\ncodeup is hosting a black excellence in tech panel in honor of black history month on february 22 2023 to further celebrate wed like to spotlight each of our panelists leading up to the discussion to learn a bit about their respective experiences as black leaders in the tech industry  \\nmeet wilmarie\\nwilmarie de la cruz mejia is a current codeup student on the path to becoming a fullstack web developer at our dallas tx campus \\nwilmarie is a veteran expanding her knowledge of programming languages and technologies on her journey with codeup \\nwe asked wilmarie to share more about her experience at codeup she shares i was able to meet other people who were passionate about coding and be in a positive learning environment\\nwe hope you can join us on february 22nd to sit in on an insightful conversation with wilmarie and all of our panelists'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_clean(codeup_df['original'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60587d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Black',\n",
       " 'excellence',\n",
       " 'in',\n",
       " 'tech',\n",
       " ':',\n",
       " 'Panelist',\n",
       " 'Spotlight',\n",
       " '–',\n",
       " 'Wilmarie',\n",
       " 'De',\n",
       " 'La',\n",
       " 'Cruz',\n",
       " 'Mejia',\n",
       " 'Codeup',\n",
       " 'is',\n",
       " 'hosting',\n",
       " 'a',\n",
       " 'Black',\n",
       " 'Excellence',\n",
       " 'in',\n",
       " 'Tech',\n",
       " 'Panel',\n",
       " 'in',\n",
       " 'honor',\n",
       " 'of',\n",
       " 'Black',\n",
       " 'History',\n",
       " 'Month',\n",
       " 'on',\n",
       " 'February',\n",
       " '22',\n",
       " ',',\n",
       " '2023',\n",
       " '!',\n",
       " 'To',\n",
       " 'further',\n",
       " 'celebrate',\n",
       " ',',\n",
       " 'we',\n",
       " '’',\n",
       " 'd',\n",
       " 'like',\n",
       " 'to',\n",
       " 'spotlight',\n",
       " 'each',\n",
       " 'of',\n",
       " 'our',\n",
       " 'panelists',\n",
       " 'leading',\n",
       " 'up',\n",
       " 'to',\n",
       " 'the',\n",
       " 'discussion',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'about',\n",
       " 'their',\n",
       " 'respective',\n",
       " 'experiences',\n",
       " 'as',\n",
       " 'black',\n",
       " 'leaders',\n",
       " 'in',\n",
       " 'the',\n",
       " 'tech',\n",
       " 'industry',\n",
       " '!',\n",
       " 'Meet',\n",
       " 'Wilmarie',\n",
       " '!',\n",
       " 'Wilmarie',\n",
       " 'De',\n",
       " 'La',\n",
       " 'Cruz',\n",
       " 'Mejia',\n",
       " 'is',\n",
       " 'a',\n",
       " 'current',\n",
       " 'Codeup',\n",
       " 'student',\n",
       " 'on',\n",
       " 'the',\n",
       " 'path',\n",
       " 'to',\n",
       " 'becoming',\n",
       " 'a',\n",
       " 'Full-Stack',\n",
       " 'Web',\n",
       " 'Developer',\n",
       " 'at',\n",
       " 'our',\n",
       " 'Dallas',\n",
       " ',',\n",
       " 'TX',\n",
       " 'campus.',\n",
       " 'Wilmarie',\n",
       " 'is',\n",
       " 'a',\n",
       " 'veteran',\n",
       " 'expanding',\n",
       " 'her',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'programming',\n",
       " 'languages',\n",
       " 'and',\n",
       " 'technologies',\n",
       " 'on',\n",
       " 'her',\n",
       " 'journey',\n",
       " 'with',\n",
       " 'Codeup.',\n",
       " 'We',\n",
       " 'asked',\n",
       " 'Wilmarie',\n",
       " 'to',\n",
       " 'share',\n",
       " 'more',\n",
       " 'about',\n",
       " 'her',\n",
       " 'experience',\n",
       " 'at',\n",
       " 'Codeup.',\n",
       " 'She',\n",
       " 'shares',\n",
       " ',',\n",
       " '“I',\n",
       " 'was',\n",
       " 'able',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'other',\n",
       " 'people',\n",
       " 'who',\n",
       " 'were',\n",
       " 'passionate',\n",
       " 'about',\n",
       " 'coding',\n",
       " 'and',\n",
       " 'be',\n",
       " 'in',\n",
       " 'a',\n",
       " 'positive',\n",
       " 'learning',\n",
       " 'environment.',\n",
       " '”',\n",
       " 'We',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'can',\n",
       " 'join',\n",
       " 'us',\n",
       " 'on',\n",
       " 'February',\n",
       " '22nd',\n",
       " 'to',\n",
       " 'sit',\n",
       " 'in',\n",
       " 'on',\n",
       " 'an',\n",
       " 'insightful',\n",
       " 'conversation',\n",
       " 'with',\n",
       " 'Wilmarie',\n",
       " 'and',\n",
       " 'all',\n",
       " 'of',\n",
       " 'our',\n",
       " 'panelists',\n",
       " '!']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(codeup_df['original'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "569dd69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Black excellence tech: Panelist Spotlight – Wilmarie De La Cruz Mejia Codeup hosting Black Excellence Tech Panel honor Black History Month February 22, 2023! To celebrate, we’d like spotlight panelists leading discussion learn bit respective experiences black leaders tech industry! Meet Wilmarie! Wilmarie De La Cruz Mejia current Codeup student path becoming Full-Stack Web Developer Dallas, TX campus. Wilmarie veteran expanding knowledge programming languages technologies journey Codeup. We asked Wilmarie share experience Codeup. She shares, “I able meet people passionate coding positive learning environment.” We hope join us February 22nd sit insightful conversation Wilmarie panelists!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(codeup_df['original'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0fb6cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Excellence in Tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>[black, excellence, tech, panelist, spotlight,...</td>\n",
       "      <td>black excel tech panelist spotlight wilmari de...</td>\n",
       "      <td>black excellence tech panelist spotlight wilma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>[black, excellence, tech, panelist, spotlight,...</td>\n",
       "      <td>black excel tech panelist spotlight stephani j...</td>\n",
       "      <td>black excellence tech panelist spotlight steph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>[black, excellence, tech, panelist, spotlight,...</td>\n",
       "      <td>black excel tech panelist spotlight jame coope...</td>\n",
       "      <td>black excellence tech panelist spotlight james...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>Black excellence in tech: Panelist Spotlight –...</td>\n",
       "      <td>[black, excellence, tech, panelist, spotlight,...</td>\n",
       "      <td>black excel tech panelist spotlight jeanic fre...</td>\n",
       "      <td>black excellence tech panelist spotlight jeani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coding Bootcamp or Self-Learning? Which is Bes...</td>\n",
       "      <td>If you’re interested in embarking on a career ...</td>\n",
       "      <td>[youre, interested, embarking, career, tech, l...</td>\n",
       "      <td>your interest embark career tech like taken lo...</td>\n",
       "      <td>youre interested embarking career tech likely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codeup Among Top 58 Best Coding Bootcamps of 2023</td>\n",
       "      <td>Codeup is pleased to announce we have been ran...</td>\n",
       "      <td>[codeup, pleased, announce, ranked, among, 58,...</td>\n",
       "      <td>codeup pleas announc rank among 58 best code b...</td>\n",
       "      <td>codeup pleased announce ranked among 58 best c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Black Excellence in Tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  Coding Bootcamp or Self-Learning? Which is Bes...   \n",
       "5  Codeup Among Top 58 Best Coding Bootcamps of 2023   \n",
       "\n",
       "                                            original  \\\n",
       "0  Black excellence in tech: Panelist Spotlight –...   \n",
       "1  Black excellence in tech: Panelist Spotlight –...   \n",
       "2  Black excellence in tech: Panelist Spotlight –...   \n",
       "3  Black excellence in tech: Panelist Spotlight –...   \n",
       "4  If you’re interested in embarking on a career ...   \n",
       "5  Codeup is pleased to announce we have been ran...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  [black, excellence, tech, panelist, spotlight,...   \n",
       "1  [black, excellence, tech, panelist, spotlight,...   \n",
       "2  [black, excellence, tech, panelist, spotlight,...   \n",
       "3  [black, excellence, tech, panelist, spotlight,...   \n",
       "4  [youre, interested, embarking, career, tech, l...   \n",
       "5  [codeup, pleased, announce, ranked, among, 58,...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  black excel tech panelist spotlight wilmari de...   \n",
       "1  black excel tech panelist spotlight stephani j...   \n",
       "2  black excel tech panelist spotlight jame coope...   \n",
       "3  black excel tech panelist spotlight jeanic fre...   \n",
       "4  your interest embark career tech like taken lo...   \n",
       "5  codeup pleas announc rank among 58 best code b...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  black excellence tech panelist spotlight wilma...  \n",
       "1  black excellence tech panelist spotlight steph...  \n",
       "2  black excellence tech panelist spotlight james...  \n",
       "3  black excellence tech panelist spotlight jeani...  \n",
       "4  youre interested embarking career tech likely ...  \n",
       "5  codeup pleased announce ranked among 58 best c...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "stemmed_text = []\n",
    "lemmatized_text= []\n",
    "\n",
    "for i in range(0, len(codeup_df)):\n",
    "    text = basic_clean(codeup_df['original'][i])\n",
    "    no_stopwords = remove_stopwords(text)\n",
    "    tokens = tokenize(no_stopwords)\n",
    "    stemmed = stem(tokens)\n",
    "    lemmatized = lemmatize(tokens)\n",
    "    \n",
    "    clean_text.append(tokens)\n",
    "    stemmed_text.append(stemmed)\n",
    "    lemmatized_text.append(lemmatized)\n",
    "\n",
    "codeup_df['clean'] = clean_text\n",
    "codeup_df['stemmed'] = stemmed_text\n",
    "codeup_df['lemmatized'] = lemmatized_text\n",
    "\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fc1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(df):\n",
    "\n",
    "    df.rename(columns={'content':'original'},  inplace= True)\n",
    "    \n",
    "    clean_text = []\n",
    "    stemmed_text = []\n",
    "    lemmatized_text= []\n",
    "\n",
    "    for i in range(0, len(df)):\n",
    "        text = basic_clean(df['original'][i])\n",
    "        no_stopwords = remove_stopwords(text)\n",
    "        tokens = tokenize(no_stopwords)\n",
    "        stemmed = stem(tokens)\n",
    "        lemmatized = lemmatize(tokens)\n",
    "\n",
    "        clean_text.append(tokens)\n",
    "        stemmed_text.append(stemmed)\n",
    "        lemmatized_text.append(lemmatized)\n",
    "\n",
    "    df['clean'] = clean_text\n",
    "    df['stemmed'] = stemmed_text\n",
    "    df['lemmatized'] = lemmatized_text\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3a34118",
   "metadata": {},
   "outputs": [],
   "source": [
    "codeup_df = add_columns(codeup_df)\n",
    "codeup_df.to_csv('clean_codeup_blogs.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebd05e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = add_columns(news_df)\n",
    "news_df.to_csv('clean_news_blogs.csv', index = False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e2f69",
   "metadata": {},
   "source": [
    "### 9. Ask yourself:\n",
    "\n",
    "    - If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "    - If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "    - If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ef0fd0",
   "metadata": {},
   "source": [
    "#### In general:\n",
    "    - lemmatize: for smaller dataset, it is slower\n",
    "    - stemming: for larger dataset, it is faster\n",
    "\n",
    "- For a corpus of 493KB, using lemmatized text may be a better option as the size of the corpus is relatively small. Lemmatization retains the base form of words, which may result in a slightly larger file size than stemming, but it can provide more accurate results as it considers the context and part of speech of the word.\n",
    "\n",
    "- For a corpus of 25MB, the decision between using stemmed or lemmatized text depends on the specific use case and requirements. Stemming is faster and results in a smaller file size, which may be beneficial if the focus is on processing speed and efficiency. On the other hand, lemmatization may be preferable if accuracy is a priority, as it produces more meaningful and contextually relevant words.\n",
    "\n",
    "- For a corpus of 200TB, using stemmed text may be a more practical option as it results in a smaller file size and can be processed faster. However, this decision also depends on the specific use case and requirements. If the accuracy of the analysis is a top priority and the added file size from lemmatization does not significantly impact the computational cost, then lemmatization may be the better option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
